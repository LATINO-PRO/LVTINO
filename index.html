<!DOCTYPE html>
<html>
<head>

  <!-- Google tag (gtag.js) -->
  <!-- TODO: replace the measurement id with yours -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-XXXXXXXXXX');
  </script> -->

  <meta charset="utf-8">

  <!-- Social media banners -->
  <meta name="description" content="LVTINO">
  <meta property="og:title" content="LVTINO"/>
  <meta property="og:description" content="LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration"/>
  <meta property="og:url" content="https://latino-pro.github.io/LVTINO/"/>
  <meta property="og:image" content="static/images/teaser.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="LVTINO">
  <meta name="twitter:description" content="LVTINO: Latent Video Consistency Inverse Solver for High Definition Video Restoration">
  <meta name="twitter:image" content="static/images/teaser.png">
  <meta name="twitter:card" content="summary_large_image">

  <meta name="keywords" content="video restoration, inverse problems, plug-and-play, diffusion, consistency models, VCM">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>LVTINO</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>

  <script>
    function setSliderAspectFromVideos(slider) {
      const vids = slider.querySelectorAll('video');
      if (vids.length !== 2) return;

      const [a, b] = vids;

      const wa = a.videoWidth  || 0, ha = a.videoHeight || 0;
      const wb = b.videoWidth  || 0, hb = b.videoHeight || 0;

      // Wait until metadata is loaded for both
      if (!wa || !ha || !wb || !hb) return;

      // Choose the “dominant” resolution to define the displayed aspect ratio.
      // (You can also choose based on area.)
      const areaA = wa * ha;
      const areaB = wb * hb;

      const W = areaA >= areaB ? wa : wb;
      const H = areaA >= areaB ? ha : hb;

      // Set slider ratio to match the higher-res video
      slider.style.aspectRatio = `${W} / ${H}`;
    }

    function initVideoComparisons() {
      const sliders = document.querySelectorAll('img-comparison-slider.video-compare');

      sliders.forEach((slider) => {
        const vids = slider.querySelectorAll('video');
        vids.forEach(v => {
          v.muted = true;
          v.playsInline = true;
          v.loop = true;
          v.preload = "metadata";
        });

        // When metadata is ready, set correct aspect ratio
        vids.forEach(v => {
          v.addEventListener('loadedmetadata', () => {
            setSliderAspectFromVideos(slider);
          }, { once: false });
        });

        // Try to start playback (muted autoplay usually works)
        vids.forEach(v => v.play().catch(() => {}));

        // Optional: sync playback times
        if (vids.length === 2) {
          const [va, vb] = vids;
          const sync = (src, dst) => {
            if (Math.abs((dst.currentTime || 0) - (src.currentTime || 0)) > 0.08) {
              dst.currentTime = src.currentTime;
            }
          };
          va.addEventListener('timeupdate', () => sync(va, vb));
          vb.addEventListener('timeupdate', () => sync(vb, va));
        }
      });
    }

    document.addEventListener('DOMContentLoaded', initVideoComparisons);
  </script>


  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        macros: {
          vx: "\\mathbf{x}",
          vy: "\\mathbf{y}",
          vz: "\\mathbf{z}",
          vu: "\\mathbf{u}",
          A: "\\mathcal{A}",
          Adag: "\\mathcal{A}^{\\dagger}",
          Id: "\\mathrm{Id}",
          encoder: "\\mathcal{E}",
          decoder: "\\mathcal{D}",
          prox: "\\operatorname{prox}",
          argmin: "\\operatorname*{arg\\,min}"
        }
      }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


  <style>
    .wide-banner { width: 100%; height: auto; display: block; }
  </style>

  <!-- Algorithm-style list -->
  <style>
    .algo-code{
      counter-reset: line;
      border: 1px solid #e1e1e1;
      border-radius: 6px;
      background: #fafafa;
      padding: 1rem 1.25rem;
      font-family: "Courier New", monospace;
      font-size: 0.92rem;
    }
    .algo-code li{
      list-style: none;
      position: relative;
      padding-left: 2.5em;
      margin: 0.25rem 0;
    }
    .algo-code li::before{
      counter-increment: line;
      content: counter(line);
      position: absolute;
      left: 0;
      width: 2em;
      text-align: right;
      color: #606060;
    }
    .algo-code .indent1{ padding-left: 3.5em; }
    .algo-code .indent1::before{ left: 1em; }
    .algo-code .indent2{ padding-left: 4.5em; }
    .algo-code .indent2::before{ left: 2em; }
  </style>

  <style>
    /* ───────────────── slider grid ───────────────── */
    .slider-grid{
      --gap: 1.25rem;
      display: grid;
      grid-template-columns: 1fr;          /* phones: 1 col */
      gap: var(--gap);
      padding: var(--gap);
      max-width: 1200px;
      margin-inline: auto;
      box-sizing: border-box;
    }

    /* tablets → 2 columns */
    @media (min-width: 600px){
      .slider-grid{ grid-template-columns: repeat(2, 1fr); }
    }

    /* desktops → 3 columns */
    @media (min-width: 992px){
      .slider-grid{ grid-template-columns: repeat(3, 1fr); }
    }

    /* ───────────────── slider look ───────────────── */
    img-comparison-slider{
      width: 100%;
      /*aspect-ratio: 1 / 1;          /* square cell */
      /* remove fixed aspect ratio; we’ll set it from JS based on the video */
      aspect-ratio: auto;
      --divider-width: 4px;
      --divider-color: #ffffffaa;
      border-radius: 8px;
      box-shadow: 0 4px 10px rgba(0,0,0,.15);
      overflow: hidden;
    }

    img-comparison-slider img,
    img-comparison-slider.video-compare{
      display: block;
    }
    img-comparison-slider.video-compare video{
      width: 100%;
      height: 100%;
      object-fit: contain;   /* preserves full frame without cropping */
      background: black;     /* avoids odd borders if aspect mismatch */
    }
  </style>

  <style>
    @media (max-width: 600px) {
      .publication-title { font-size: 1.75rem !important; line-height: 1.2; }
    }
    @media (min-width: 600px) {
      figure.has-text-centered img, figure.has-text-centered figcaption, ol.algo-code {
        width: 80%; height: auto; margin: 0 auto;
      }
    }
    @media (min-width: 992px) {
      figure.has-text-centered img, figure.has-text-centered figcaption, ol.algo-code {
        width: 60%; height: auto; margin: 0 auto;
      }
    }
  </style>

  <style>
    /* lightweight, reusable tooltip */
    .coming-tooltip{
      position: fixed;
      pointer-events: none;
      background: #222;
      color: #fff;
      font-size: 0.8rem;
      padding: 0.3em 0.55em;
      border-radius: 4px;
      white-space: nowrap;
      opacity: 0;
      transition: opacity 0.2s ease;
      z-index: 10000;
    }
  </style>

</head>

<body>

  <!-- Header / title -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://scholar.google.com/citations?user=Xmr-06oAAAAJ&hl=en" target="_blank">Alessio Spagnoletti</a>, <a href="https://scholar.google.com/citations?user=e1pFlV0AAAAJ&hl=en" target="_blank">Andrés Almansa</a>, <a href="https://scholar.google.com/citations?user=ep85sxQAAAAJ&hl=en" target="_blank">Marcelo Pereyra</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="conf-block">ICLR 2026</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <!-- Paper -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2510.01339.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Code -->
                <span class="link-block">
                  <!-- TODO: point this to your repo -->
                  <a id="github-btn" href="https://github.com/LATINO-PRO/LVTINO" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- arXiv -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2510.01339" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv</span>
                  </a>
                </span>

              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Video slider -->
  <section class="hero is-small">
    <div class="slider-grid">

      <!-- Slider 1 -->
      <img-comparison-slider value="50" class="video-compare">
        <video slot="first"  src="static/videos/video1/obs.mp4"  muted playsinline loop preload="metadata"></video>
        <video slot="second" src="static/videos/video1/out.mp4" muted playsinline loop preload="metadata"></video>
      </img-comparison-slider>

      <!-- Slider 2 -->
      <img-comparison-slider value="50" class="video-compare">
        <video slot="first"  src="static/videos/video2/obs.mp4"  muted playsinline loop preload="metadata"></video>
        <video slot="second" src="static/videos/video2/out.mp4" muted playsinline loop preload="metadata"></video>
      </img-comparison-slider>

      <!-- Slider 3 -->
      <img-comparison-slider value="50" class="video-compare">
        <video slot="first" src="static/videos/video3/obs.mp4" muted playsinline loop autoplay preload="auto"></video>
        <video slot="second" src="static/videos/video3/out.mp4" muted playsinline loop preload="metadata"></video>
      </img-comparison-slider>

      <!-- Slider 4 -->
      <img-comparison-slider value="50" class="video-compare">
        <video slot="first"  src="static/videos/video1/obs.mp4"  muted playsinline loop preload="metadata"></video>
        <video slot="second" src="static/videos/video1/out.mp4" muted playsinline loop preload="metadata"></video>
      </img-comparison-slider>

      <!-- Slider 5 -->
      <img-comparison-slider value="50" class="video-compare">
        <video slot="first"  src="static/videos/video2/obs.mp4"  muted playsinline loop preload="metadata"></video>
        <video slot="second" src="static/videos/video2/out.mp4" muted playsinline loop preload="metadata"></video>
      </img-comparison-slider>

      <!-- Slider 6 -->
      <img-comparison-slider value="50" class="video-compare">
        <video slot="first" src="static/videos/video3/obs.mp4" muted playsinline loop autoplay controls preload="auto"></video>
        <video slot="second" src="static/videos/video3/out.mp4" muted playsinline loop preload="metadata"></video>
      </img-comparison-slider>

      <!-- Add more sliders as needed -->

    </div>
  </section>
  <!-- End video slider -->

  <!-- Abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>Computational imaging methods increasingly rely on powerful generative diffusion models to tackle challenging image restoration tasks. In particular, state-of-the-art zero-shot image inverse solvers leverage distilled text-to-image latent diffusion models (LDMs) to achieve unprecedented accuracy and perceptual quality with high computational efficiency. However, extending these advances to high-definition video restoration remains a significant challenge, due to the need to recover fine spatial detail while capturing subtle temporal dependencies. Consequently, methods that naively apply image-based LDM priors on a frame-by-frame basis often result in temporally inconsistent reconstructions. We address this challenge by leveraging recent advances in Video Consistency Models (VCMs), which distill video latent diffusion models into fast generators that explicitly capture temporal causality. Building on this foundation, we propose LVTINO, the first zero-shot or plug-and-play inverse solver for high definition video restoration with priors encoded by VCMs. Our conditioning mechanism bypasses the need for automatic differentiation and achieves state-of-the-art video reconstruction quality with only a few neural function evaluations, while ensuring strong measurement consistency and smooth temporal transitions across frames. Extensive experiments on a diverse set of video inverse problems show significant perceptual improvements over current state-of-the-art methods that apply image LDMs frame by frame, establishing a new benchmark in both reconstruction fidelity and computational efficiency.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser -->
  <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/images/teaser.png" alt="LVTINO teaser figure" class="wide-banner">
      <figcaption class="has-text-grey is-size-6 mt-2">
        Results on joint spatial-temporal super-resolution by factor ×8.
      </figcaption>
    </figure>
  </div>

  <!-- Method overview -->
  <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/images/pipe.png" alt="One solver step" class="wide-banner">
      <figcaption class="has-text-grey is-size-6 mt-2">
        One solver step (two SAE prior half-steps + two proximal likelihood steps) in LVTINO.
      </figcaption>
    </figure>
  </div>

  <!-- Algorithm -->
  <figure class="my-5">
    <figcaption class="has-text-weight-bold has-text-centered mb-2">
      Algorithm&nbsp;1:&nbsp;LVTINO
    </figcaption>

    <ol class="algo-code">
      <li>
        <strong>Given</strong> degraded video $\vy$, operator $\A$,
        initialization $\vx^{(0)} = \Adag \vy$, video length $T+1$, steps $N=5$.
      </li>

      <li>
        <strong>Given</strong> video CM $(\encoder_V,\decoder_V,f^V_{\vartheta})$,
        image CM $(\encoder_I,\decoder_I,f^I_{\theta})$,
        schedules $\{t^{(V)}_k,\, t^{(I)}_k,\, \delta_k,\, \eta,\, \lambda\}_{k=0}^{N-1}$,
        data term $g_{\vy}$.
      </li>

      <li><strong>For</strong> $k=0,\ldots,N-1$</li>

      <li class="indent1"><em># VCM prior half-step (temporal coherence)</em></li>
      <li class="indent1">$\epsilon_V \sim \mathcal{N}(0,\Id)$</li>
      <li class="indent1">
        $\vz^{(V)}_{t^{(V)}_k} \leftarrow
        \sqrt{\alpha_{t^{(V)}_k}}\,\encoder_V\!\bigl(\vx^{(k)}\bigr) +
        \sqrt{1-\alpha_{t^{(V)}_k}}\,\epsilon_V$
      </li>
      <li class="indent1">
        $\tilde{\vx}^{(k+1/4)} \leftarrow
        \decoder_V\!\bigl(f^V_{\vartheta}(\vz^{(V)}_{t^{(V)}_k},\, t^{(V)}_k)\bigr)$
      </li>

      <li class="indent1"><em># First likelihood step (prox-splitting / Adam)</em></li>
      <li class="indent1">
        $\tilde{\vx}^{(k+1/2)} \leftarrow
        \argmin_{u}\; g_{\vy}(u) + \phi_{\lambda}(u) +
        \frac{1}{2\delta_k\eta}\,\bigl\|\tilde{\vx}^{(k+1/4)}-u\bigr\|_2^2$
      </li>

      <li class="indent1"><strong>If</strong> $k < N-1$</li>

      <li class="indent2"><em># ICM prior half-step (per-frame detail)</em></li>
      <li class="indent2">$\epsilon_I \sim \mathcal{N}(0,\Id)$</li>
      <li class="indent2">
        $\tilde{\vx}^{(k+3/4)} \leftarrow
        \operatorname{stack}_{\tau=0}^T\;
        \decoder_I\!\Bigl(
          f^I_{\theta}\bigl(
            \sqrt{\alpha_{t^{(I)}_k}}\,\encoder_I(\tilde{\vx}^{(k+1/2)},\,\tau) +
            \sqrt{1-\alpha_{t^{(I)}_k}}\,\epsilon_I,\;
            t^{(I)}_k
          \bigr)
        \Bigr)$
      </li>

      <li class="indent2"><em># Second likelihood step (CG in practice)</em></li>
      <li class="indent2">
        $\vx^{(k+1)} \leftarrow
        \argmin_{u}\; g_{\vy}(u) +
        \frac{1}{2\delta_k(1-\eta)}\,\bigl\|\tilde{\vx}^{(k+3/4)}-u\bigr\|_2^2$
      </li>

      <li class="indent1"><strong>Else</strong> $\vx^{(k+1)} \leftarrow \tilde{\vx}^{(k+1/2)}$</li>

      <li><strong>Return</strong> $\vx^{(N)}$</li>
    </ol>
  </figure>


  <!-- Quantitative results -->
  <!-- <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/tables/table_adobe240.png" alt="Table Adobe240">
      <figcaption class="has-text-grey is-size-6 mt-2">Adobe240: quantitative results across Problems A/B/C (best in bold, second best underlined in the paper).</figcaption>
    </figure>
  </div>

  <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/tables/table_gopro240.png" alt="Table GoPro240">
      <figcaption class="has-text-grey is-size-6 mt-2">GoPro240: quantitative results across Problems A/B/C (best in bold, second best underlined in the paper).</figcaption>
    </figure>
  </div>

  <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/tables/table_runtime_memory.png" alt="Table runtime and memory">
      <figcaption class="has-text-grey is-size-6 mt-2">Runtime & memory footprint (25 frames at 1280×768) as reported in the paper.</figcaption>
    </figure>
  </div> -->

  <!-- Visual comparisons -->
  <!-- <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/images/figure3_slices.png" alt="Slices comparison">
      <figcaption class="has-text-grey is-size-6 mt-2">Fixed-column (i, τ) slices over 81 consecutive frames for Problem C (seq. C2): LVTINO reduces flicker and improves temporal consistency.</figcaption>
    </figure>
  </div>

  <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/images/figure4_visual_comparison.png" alt="Visual comparison Problem A">
      <figcaption class="has-text-grey is-size-6 mt-2">Problem A (seq. A1): LVTINO recovers coherent motion while sharpening spatial details.</figcaption>
    </figure>
  </div>

  <div class="my-5">
    <figure class="has-text-centered">
      <img src="static/images/figure5_visual_comparison.png" alt="Visual comparison Problem B">
      <figcaption class="has-text-grey is-size-6 mt-2">Problem B (seq. B2): LVTINO mitigates flickering artifacts compared to an image-based baseline.</figcaption>
    </figure>
  </div> -->

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{spagnoletti2025lvtino,
      title={LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration}, 
      author={Alessio Spagnoletti and Andrés Almansa and Marcelo Pereyra},
      year={2025},
      eprint={2510.01339},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.01339},
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the
              <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>
              which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br>
              This website is licensed under a
              <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


  <script>
    (function () {
      const btn = document.getElementById('github-btn');
      if (!btn) return;

      const tip = Object.assign(document.createElement('div'), {
        className: 'coming-tooltip',
        textContent: 'Coming soon!'
      });
      document.body.appendChild(tip);

      btn.addEventListener('click', (e) => {
        e.preventDefault();
        tip.style.left = (e.clientX + 12) + 'px';
        tip.style.top  = (e.clientY - 12) + 'px';
        tip.style.opacity = '1';
        clearTimeout(tip._hideTimer);
        tip._hideTimer = setTimeout(() => tip.style.opacity = '0', 1200);
      });
    })();
  </script>

</body>
</html>
